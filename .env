# SERVER Configuration
LLM_SERVER_URL="http://localhost:11434"
#LLM_SERVER_URL="http://localhost:11435"

#MODEL Name
#MODEL_NAME="mistral:latest"
MODEL_NAME="zephyr:latest"

#MODEL_NAME="llama2:7b"
#MODEL_NAME="mistral-openorca:latest"

## MODEL parameter
MODEL_TEMPERATURE=0.1

# EMBEDDING_MODEL
EMBEDDING_MODEL_NAME="hkunlp/instructor-large"

# VECTOR DB Location
DB_DIRECTORY="./DB_Fusion"
#DB_DIRECTORY="./DB_TSM"

# CHAT UI Configuration
#CHAT_UI_TITLE="IBM Storage protect AI Assistant"
CHAT_UI_TITLE="IBM Storage Fusion AI Assistant"
#CHAT_UI_INPUT_PLACEHOLDER="Please ask me questions only for IBM Storage Protect(TSM)"
CHAT_UI_INPUT_PLACEHOLDER="Please ask me questions only for IBM Storage Fusion"
#CHAT_UI_PORT
CHAT_UI_PORT=5006
