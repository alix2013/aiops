# Large Language Model Server Configuration

LLM_SERVER_URL="http://localhost:11434"
# LLM_SERVER_URL="http://llmserver-aiops.apps.hci1.pbm.ihost.com"
#LLM_SERVER_URL="https://api.openai.com/v1"
# LLM_SERVER_URL="https://api.groq.com/openai/v1"

#LLM_SERVER_URL="https://postcard-ut-renew-richardson.trycloudflare.com/v1"
# LLM_SERVER_URL="https://travesti-andorra-christmas-differential.trycloudflare.com/v1"
#LLM_SERVER_URL="http://localhost:8000"
# LLM_SERVER_URL="http://localhost/v1"
# LLM_SERVER_URL="https://api.openai.com/v1"

# SERVER_TYPE is openai compatible or not
# LLM_SERVER_TYPE="openai"

#MODEL Name
# MODEL_NAME="mistral:latest"
# MODEL_NAME="llama3"
MODEL_NAME="phi3"
# MODEL_NAME="mistral_fusion_v1"
# MODEL_NAME="mixtral-8x7b-32768"
# MODEL_NAME="mixtral"
#MODEL_NAME="gemma:latest"
# MODEL_NAME="gpt-3.5-turbo"

# MODEL_NAME="neural-chat"
#MODEL_NAME="mistral:7b-instruct-q6_K"
#MODEL_NAME="openhermes2-mistral"

# MODEL_NAME="zephyr:latest"
#MODEL_NAME="llama2:7b"
# MODEL_NAME="mistral-openorca:latest"

## MODEL parameter
#MODEL_TEMPERATURE=0
MODEL_TEMPERATURE=0.2

# ACTION_MODEL_NAME="neural-chat"
ACTION_MODEL_NAME="mixtral-8x7b-32768"
ACTION_MODEL_TEMPERATURE=0
# EMBEDDING_MODEL
EMBEDDING_MODEL_NAME="hkunlp/instructor-large"
#SENTENCE_TRANSFORMERS_HOME="~/.cache/torch/sentence_transformers"

# VECTOR DB Location
DB_DIRECTORY="./DB_Fusion"
# DB_DIRECTORY="/Users/alex/Downloads/vectorDB/DB_TSM_1"
# DB_DIRECTORY="./DB_TSM"

# CHAT UI Configuration
#CHAT_UI_TITLE="IBM Storage protect AI Assistant"
CHAT_UI_TITLE="IBM Storage Fusion AI Assistant"
#CHAT_UI_INPUT_PLACEHOLDER="Please ask me questions only for IBM Storage Protect(TSM)"
CHAT_UI_INPUT_PLACEHOLDER="Please ask me questions only for IBM Storage Fusion"
#CHAT_UI_PORT
CHAT_UI_PORT=5006

# Vector DB source directory 
SOURCE_DIRECTORY="./SOURCE_DIRECTORY"

SHOW_SOURCE_DOC="True"
RAG_ENABLED="True"
